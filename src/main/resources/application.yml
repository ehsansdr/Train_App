spring:
#  kafka:
#    bootstrap-servers: 192.168.110.243:19091 # Kafka broker address(es)
#
#    producer:
#      key-serializer: org.apache.kafka.common.serialization.StringSerializer # Serializer for the key of the Kafka message (String in this case)
#      value-serializer: org.springframework.kafka.support.serializer.JsonSerializer # Serializer for the value of the Kafka message (using Spring's JsonSerializer for JSON)
#      properties:
#        spring:
#          kafka:
#            json:
#              add:
#                type:
#                  headers: true # This property tells the JsonSerializer to add type information to the message headers
#
#    consumer:
#      bootstrap-servers: 192.168.110.243:19091 # Replace with your Kafka brokers
#      group-id: ${my.kafka.consumer-group-id}         # Replace with your desired group ID
#      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer # Deserializer for the key of the Kafka message (String in this case)
#      value-deserializer: org.springframework.kafka.support.serializer.JsonDeserializer # Deserializer for the value of the Kafka message (using Spring's JsonDeserializer for JSON)
#      auto-offset-reset: latest             # Or earliest
#      enable-auto-commit: true             # Default is true
#      auto-commit-interval: 5000           # in milliseconds (default: 5000)
#      max-poll-records: 500                # Maximum number of records to fetch in a single poll
#      fetch-min-bytes: 1024                # Minimum amount of data the server should return for a fetch request
#      fetch-max-wait: 1000                # Maximum amount of time the server will block before answering the fetch request if there isn't sufficient data
#      properties:
#        spring:
#          json:
#            value:
#              default:
#                type: com.example.trainproject.Model.KafkaProduceMessage # Explicitly set the default type for deserialization if no type header is found
#            trusted:
#              packages: com.example.trainproject.Model # Add the package of your KafkaProduceMessage class to allow deserialization
#              # Add other trusted package names here, separated by commas, if you have other models to consume

  kafka:
    bootstrap-servers: localhost:9092
    admin:
      auto-create: true
    consumer:
      group-id: my-group
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.ByteArraySerializer
    listener:
      concurrency: 3

# for pre-build part
#  kafka:
#    # Kafka producer settings
#    producer:
#      bootstrap-servers: 192.168.110.243:19091  # Kafka broker to connect to (IP:port)
#      key-serializer: org.apache.kafka.common.serialization.StringSerializer  # Serializer for the key (converts key into byte array)
#      value-serializer: org.apache.kafka.common.serialization.StringSerializer  # Serializer for the value (converts value into byte array)

  #    # Kafka consumer settings
  #    consumer:
  #      bootstrap-servers: kafka1:19091  # Kafka broker to connect to (IP:port)
  #      group-id: test-group  # Consumer group id. Kafka uses this to group consumers together
  #      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer  # Deserializer for the key (converts byte array into key)
  #      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer  # Deserializer for the value (converts byte array into value)

  datasource:
    url: jdbc:mysql://localhost:3306/train_db  # Replace with your DB name
    username: root  # Your MySQL username (NOT root for production!)
    password: P@ssw0rd # Your MySQL password
    driver-class-name: com.mysql.cj.jdbc.Driver # Essential for MySQL

  jpa:
    hibernate:
      ddl-auto: update # Or create, none, validate, etc.  'update' is good for development
    show-sql: true  # Optional: Show SQL in console (for debugging)
    properties:
      hibernate.format_sql: true # Optional: Format SQL in logs
  liquibase:
    change-log: classpath:/db/changelog/db.changelog-master.yaml
  # Optional - If you want to configure a naming strategy for your tables/columns
  # jpa:
  #   hibernate:
  #     naming:
  #       physical-strategy: org.hibernate.boot.model.naming.PhysicalNamingStrategyStandardImpl # Or a custom strategy

server:
  port: 8080 # Or your preferred port


# Logging configuration (optional)
logging:
  level:
    root: INFO  # Or DEBUG for more detailed output
    org.hibernate.SQL: DEBUG # To see SQL statements
    org.hibernate.type.descriptor.sql: TRACE # To see data binding


my:
  kafka:
    topic: "kafka_training_Es"
    consumer-group-id: "my-consumer-group-id"

kafka-info:
  topics:
    notification: NOTIFICATION_TOPIC
